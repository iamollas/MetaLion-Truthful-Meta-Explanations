{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative experiments with Credit Card Approval dataset\n",
    "This dataset contains information about bank customers, as well as information regarding theirÂ debt payments (if any). https://cutt.ly/xQ1mqyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\iamollas\\\\Desktop\\\\Altruist New')\n",
    "model_path = 'C:\\\\Users\\\\iamollas\\\\Desktop\\\\Altruist New\\\\experiments\\\\quantitative\\\\Models\\\\D2\\\\'\n",
    "weights_path = 'C:\\\\Users\\\\iamollas\\\\Desktop\\\\Altruist New\\\\experiments\\\\quantitative\\\\Weights\\\\D2\\\\'\n",
    "data_path = 'C:\\\\Users\\\\iamollas\\\\Desktop\\\\Altruist New\\\\experiments\\\\quantitative\\\\Preprocessed Data\\\\D2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "import warnings\n",
    "import json\n",
    "import lime.lime_tabular as lt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, concatenate\n",
    "import json\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from innvestigate.utils.keras import checks\n",
    "import innvestigate\n",
    "import innvestigate.utils as iutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from altruist import Altruist\n",
    "from meta_explain import MetaExplain\n",
    "from utilities.dataset import Dataset\n",
    "from sklearn.preprocessing import maxabs_scale\n",
    "import numpy as np\n",
    "np.seterr(invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the Credit Approval dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in final dataset: (35442, 13)\n",
      "Original dataset shape Counter({0: 34846, 1: 596})\n",
      "TomekLinks: Resampled dataset shape Counter({0: 34649, 1: 596})\n",
      "NC: Resampled dataset shape Counter({0: 33196, 1: 596})\n",
      "NM: Resampled dataset shape Counter({0: 596, 1: 596})\n",
      "Random: Resampled dataset shape Counter({0: 596, 1: 596})\n"
     ]
    }
   ],
   "source": [
    "credit = Dataset()\n",
    "X_res, X, y_res, y, feature_names = credit.load_credit_approval(\n",
    "    original_data_available=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42)\n",
    "class_names = ['Denial', 'Approval']\n",
    "feature_names = list(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will build two neural network models. One linear and one non-linear, and one uneccessary complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "transformer = MaxAbsScaler().fit(X_train)\n",
    "\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iamollas\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\Users\\iamollas\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "linear_neural = Sequential()\n",
    "linear_neural.add(Dense(1, activation='sigmoid',\n",
    "                        input_shape=(len(X_train[0]),)))\n",
    "linear_neural.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "neural = Sequential()\n",
    "neural.add(Dense(160, activation='relu', input_shape=(len(X_train[0]),)))\n",
    "neural.add(Dense(80, activation='tanh'))\n",
    "neural.add(Dense(40, activation='tanh'))\n",
    "neural.add(Dense(20, activation='tanh'))\n",
    "neural.add(Dense(16, activation='tanh'))\n",
    "neural.add(Dense(1, activation='sigmoid'))\n",
    "neural.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "complex_input = Input(shape=(len(X_train[0]),))\n",
    "complex_r = []\n",
    "for i in range(12):\n",
    "    temp_layer = Dense(units=128, activation='relu')(complex_input)\n",
    "    temp_layer = Dropout(0.3)(temp_layer)\n",
    "    temp_layer = Dense(units=64, activation='selu')(temp_layer)\n",
    "    temp_layer = Dropout(0.3)(temp_layer)\n",
    "    temp_layer = Dense(units=32, activation='selu')(temp_layer)\n",
    "    complex_r.append(temp_layer)\n",
    "complex_r.append(complex_input)\n",
    "complex = concatenate(complex_r)\n",
    "complex = Dropout(0.3)(complex)\n",
    "complex = Dense(160, activation='tanh')(complex)\n",
    "complex = concatenate([complex, complex_input])\n",
    "complex = Dropout(0.3)(complex)\n",
    "complex = Dense(100, activation='tanh')(complex)\n",
    "complex = Dropout(0.3)(complex)\n",
    "complex_output = Dense(1, activation='sigmoid')(complex)\n",
    "complex_neural = Model(complex_input, complex_output)\n",
    "complex_neural.compile(optimizer=\"adam\", loss=['binary_crossentropy'])\n",
    "\n",
    "models = {'lNN': linear_neural, 'NN': neural, 'cNN': complex_neural}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def compute_scores(name, y_test, y_pred):\n",
    "    if type(y_pred[0]) == type(np.ndarray([1])):\n",
    "        y_pred = np.array([1 if i[0] > 0.5 else 0 for i in y_pred])\n",
    "    print(name)\n",
    "    print('\\t', 'F1:', f1_score(y_test, y_pred, average='macro'))\n",
    "    print('\\t', 'Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "    print('\\t', 'Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "    print('\\t', 'Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\iamollas\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "lNN\n",
      "\t F1: 0.5856579984239558\n",
      "\t Precision: 0.5857863751051303\n",
      "\t Recall: 0.5857142857142856\n",
      "\t Accuracy: 0.5857740585774058\n",
      "NN\n",
      "\t F1: 0.6945392790237582\n",
      "\t Precision: 0.694565065135173\n",
      "\t Recall: 0.6945378151260504\n",
      "\t Accuracy: 0.694560669456067\n",
      "cNN\n",
      "\t F1: 0.7027415257948673\n",
      "\t Precision: 0.7032631578947368\n",
      "\t Recall: 0.7028361344537815\n",
      "\t Accuracy: 0.702928870292887\n"
     ]
    }
   ],
   "source": [
    "train = False\n",
    "for name, model in models.items():\n",
    "    if train:\n",
    "        check_point = ModelCheckpoint(\n",
    "            \"D2_\"+name+\".hdf5\", monitor=\"val_loss\", verbose=0, save_best_only=True, mode=\"auto\")\n",
    "        model.fit(X_train, y_train, epochs=500, batch_size=32,\n",
    "                  validation_split=0.2, verbose=0, callbacks=[check_point])\n",
    "        model.load_weights(\"D2_\"+name+\".hdf5\")\n",
    "    else:\n",
    "        model.load_weights(model_path+\"D2_\"+name+\".hdf5\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    compute_scores(name, y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prepare our predict functions to work well with our python scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cNN(x):\n",
    "    prediction = models['cNN'].predict(x)\n",
    "    return [i[0] for i in prediction]\n",
    "\n",
    "def predict_NN(x):\n",
    "    prediction = models['NN'].predict(x)\n",
    "    return [i[0] for i in prediction]\n",
    "\n",
    "def predict_lNN(x):\n",
    "    prediction = models['lNN'].predict(x)\n",
    "    return [i[0] for i in prediction]\n",
    "\n",
    "predict_functions = {'lNN': predict_lNN, 'NN': predict_NN, 'cNN': predict_cNN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inxai import *\n",
    "gm = GlobalFeatureMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 239 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "100%|ââââââââââ| 239/239 [17:44<00:00,  4.45s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8124f9634993>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGlobalFeatureMetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshap_res\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_per_instance_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lNN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel_shap'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlime_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_per_instance_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lNN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lime'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Altruist New\\inxai\\global_metrics.py\u001b[0m in \u001b[0;36mgenerate_per_instance_importances\u001b[1;34m(models, X, y, framework)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mall_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLimeTabularExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "from inxai import *\n",
    "gm = GlobalFeatureMetric()\n",
    "shap_res=generate_per_instance_importances(models=models['lNN'], X=X_test, y=y_test, framework='kernel_shap')\n",
    "lime_res = generate_per_instance_importances(models=models['lNN'], X=X_test, y=y_test, framework='lime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "def minmaxdf(df, scale=[-1,1]):\n",
    "    # Using MinMaxScaler\n",
    "    min_max_scaler = MinMaxScaler(feature_range=scale)    \n",
    "    # Stack everything into a single column to scale by the global min / max\n",
    "    tmp = df.to_numpy().reshape(-1,1)\n",
    "    scaled = min_max_scaler.fit_transform(tmp).reshape(len(df), df.shape[1])\n",
    "    return scaled\n",
    "    \n",
    "shap_res = minmaxdf(pd.DataFrame(shap_res), scale=[-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_lips = gm.stability(pd.DataFrame(X_test),shap_res ,epsilon=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8898531835353339"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(shape_lips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our explainers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer_generators(model):\n",
    "    Xs = iutils.to_list(model.outputs)\n",
    "    ret = []\n",
    "    for x in Xs:\n",
    "        layer, node_index, tensor_index = x._keras_history\n",
    "        if checks.contains_activation(layer, activation=\"sigmoid\"):\n",
    "            if isinstance(layer, keras.layers.Activation):\n",
    "                ret.append(layer.get_input_at(node_index))\n",
    "            else:\n",
    "                layer_wo_act = innvestigate.utils.keras.graph.copy_layer_wo_activation(\n",
    "                    layer)\n",
    "                ret.append(layer_wo_act(layer.get_input_at(node_index)))\n",
    "    modified_model = Model(input=model.input, output=ret)\n",
    "    modified_model.trainable = False\n",
    "    modified_model.compile(optimizer=\"adam\", loss=[\n",
    "                           'binary_crossentropy'], metrics=['accuracy'])\n",
    "    analyzer_IG = innvestigate.create_analyzer(\n",
    "        'integrated_gradients', modified_model, reference_inputs=16*[0])\n",
    "    analyzer_LRP = innvestigate.create_analyzer('lrp.z', modified_model)\n",
    "    return [analyzer_IG, analyzer_LRP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_NN = analyzer_generators(neural)\n",
    "analyzer_lNN = analyzer_generators(linear_neural)\n",
    "analyzer_cNN = analyzer_generators(complex_neural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare each interpretation technique to have the same format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fi_lNN(instance, predict_function):\n",
    "    return [i[0] for i in models['lNN'].get_weights()[0]]\n",
    "\n",
    "def fi_IG_NN(instance, predict_function):\n",
    "    return analyzer_NN[0].analyze(np.array([instance]))[0]\n",
    "\n",
    "def fi_LRP_NN(instance, predict_function):\n",
    "    return analyzer_NN[1].analyze(np.array([instance]))[0]\n",
    "\n",
    "def fi_IG_lNN(instance, predict_function):\n",
    "    return analyzer_lNN[0].analyze(np.array([instance]))[0]\n",
    "\n",
    "def fi_LRP_lNN(instance, predict_function):\n",
    "    return analyzer_lNN[1].analyze(np.array([instance]))[0]\n",
    "\n",
    "def fi_IG_cNN(instance, predict_function):\n",
    "    return analyzer_cNN[0].analyze(np.array([instance]))[0]\n",
    "\n",
    "def fi_LRP_cNN(instance, predict_function):\n",
    "    return analyzer_cNN[1].analyze(np.array([instance]))[0]\n",
    "\n",
    "explainer = lt.LimeTabularExplainer(training_data=X_train,\n",
    "                                    feature_names=feature_names, class_names=class_names,\n",
    "                                    discretize_continuous=True, mode='regression')\n",
    "\n",
    "def fi_lime(instance, predict_function):\n",
    "    def predict(x):\n",
    "        return np.array([i for i in predict_function(x)])\n",
    "    b = explainer.explain_instance(instance, predict,\n",
    "                                   num_features=len(list(feature_names)))[0].local_exp\n",
    "    b = b[list(b.keys())[0]]\n",
    "    b.sort()\n",
    "    return [i[1] for i in list(b)]\n",
    "\n",
    "def fi_random(instance, predict_function):\n",
    "    seed = (instance[0].sum() +\n",
    "            instance[0].mean() +\n",
    "            X_train[0][0] +\n",
    "            X_train[0][1])/10\n",
    "    random.seed(seed)\n",
    "    return [random.randrange(-1000, 1000)/1000 for i in range(len(feature_names))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute and save the interpretations for easier reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "\n",
    "    importance_train = []\n",
    "    for instance in X_train:\n",
    "        importance_instance = []\n",
    "        for fi in fi_techniques:\n",
    "            importance_instance.append(maxabs_scale(fi(instance, neural_type)))\n",
    "        importance_train.append(importance_instance)\n",
    "    importance_train = np.array(importance_train)\n",
    "\n",
    "    importance_test = []\n",
    "    for instance in X_test:\n",
    "        importance_instance = []\n",
    "        for fi in fi_techniques:\n",
    "            importance_instance.append(maxabs_scale(fi(instance, neural_type)))\n",
    "        importance_test.append(importance_instance)\n",
    "    importance_test = np.array(importance_test)\n",
    "\n",
    "    importances = {'train': importance_train.tolist(),\n",
    "                   'test': importance_test.tolist()}\n",
    "    with open('D2_'+neural_name+'.txt', 'w') as outfile:\n",
    "        json.dump(importances, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quantitative experiments!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with stability! First, we calculate stability for the aforementioned techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNN\n",
      "Inherent 1.0\n",
      "IG 0.8404501665224063\n",
      "LRP 0.8404501329297139\n",
      "LIME 0.6809600622317692\n",
      "RAND 0.8308214326825123\n",
      "NN\n",
      "IG 0.729764891052372\n",
      "LRP 0.7346200777516944\n",
      "LIME 0.6882271689614915\n",
      "RAND 0.8308214326825123\n",
      "cNN\n",
      "IG 0.704309474078126\n",
      "LRP 0.7069742868357708\n",
      "LIME 0.6849819692559148\n",
      "RAND 0.8308214326825123\n"
     ]
    }
   ],
   "source": [
    "stability = {}\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    meta_names = ['Average', 'Median', 'RuleBased']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "    meta_explain = MetaExplain(importance_train, feature_names)\n",
    "\n",
    "    model_stability = []\n",
    "    for idf,fi_name in enumerate(fi_names):\n",
    "        model_stability.append(gm.stability(pd.DataFrame(X_test),importance_test[:,idf,:] ,epsilon=0.3))\n",
    "    stability[neural_name] = model_stability\n",
    "    \n",
    "    print(neural_name)\n",
    "    for idf, stability_score in enumerate(stability[neural_name]):\n",
    "        print(fi_names[idf], np.mean(stability_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for lNN\n",
      "Average 0.8739009780555776\n",
      "Median 0.8591818124134086\n",
      "RuleBased 0.7815326847286\n",
      "Starting evaluation for NN\n",
      "Average 0.7849013122232625\n",
      "Median 0.7593617694007542\n",
      "RuleBased 0.7413138671251036\n",
      "Starting evaluation for cNN\n",
      "Average 0.7689817890825743\n",
      "Median 0.7411816739541573\n",
      "RuleBased 0.7353874670364865\n"
     ]
    }
   ],
   "source": [
    "meta_interpretations_test = {}\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "        meta_interpretations_test['lNN'] = []\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "        meta_interpretations_test['NN'] = []\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "        meta_interpretations_test['cNN'] = []\n",
    "    meta_names = ['Average', 'Median', 'RuleBased']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "    meta_explain = MetaExplain(importance_train, feature_names)\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    noise = 'normal'\n",
    "    delta = 0.0001\n",
    "\n",
    "    my_altruist = Altruist(\n",
    "        neural_type, X_train, fi_techniques, feature_names, level=noise, delta=delta)\n",
    "    for j in range(len(X_test)):\n",
    "        my_altruist.fis = len(fi_techniques)\n",
    "        a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "        b = np.array(a[-1])\n",
    "\n",
    "        temp_meta = []\n",
    "        temp_meta.append(meta_explain.meta_avg(b))\n",
    "        temp_meta.append(meta_explain.meta_median(b))\n",
    "        temp_meta.append(meta_explain.meta_rule_based(a[0], a[2], b))\n",
    "        meta_interpretations_test[neural_name].append(temp_meta)\n",
    "    \n",
    "    model_stability = []\n",
    "    for idf,meta_name in enumerate(meta_names):\n",
    "        model_stability.append(gm.stability(pd.DataFrame(X_test),np.array(meta_interpretations_test[neural_name])[:,idf,:] ,epsilon=0.3))\n",
    "    stability_meta[neural_name] = model_stability\n",
    "\n",
    "    for idf, stability_score in enumerate(stability_meta[neural_name]):\n",
    "        print(meta_names[idf], np.mean(stability_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cb1b58c448>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "lip_df = pd.DataFrame({'IG':stability['cNN'][0], 'LRP':stability['cNN'][1], 'LIME':stability['cNN'][2], # 'RAND':stability['cNN'][3], \n",
    "                        'Average':stability_meta['cNN'][0], 'Median':stability_meta['cNN'][1], 'MetaLion':stability_meta['cNN'][2]})\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(lip_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_df_lnn = pd.DataFrame({'IG':stability['lNN'][1], 'LRP':stability['lNN'][2], 'LIME':stability['lNN'][3], 'RAND':stability['lNN'][4]})\n",
    "lip_df_nn = pd.DataFrame({'IG':stability['NN'][0], 'LRP':stability['NN'][1], 'LIME':stability['NN'][2], 'RAND':stability['NN'][3]})\n",
    "lip_df_cnn = pd.DataFrame({'IG':stability['cNN'][0], 'LRP':stability['cNN'][1], 'LIME':stability['cNN'][2], 'RAND':stability['cNN'][3]})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Consistency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG 0.39185751014124026\n",
      "LRP 0.4009673039690312\n",
      "LIME 0.47351908914599683\n",
      "RAND 1.0\n"
     ]
    }
   ],
   "source": [
    "consistency = {}\n",
    "for idf,fi_name in enumerate(['IG', 'LRP', 'LIME', 'RAND']):\n",
    "    all_importance_tests = []\n",
    "    for neural_name, neural_type in predict_functions.items():\n",
    "\n",
    "        with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "            importances = json.load(json_file)\n",
    "        if neural_name == 'lNN':\n",
    "            all_importance_tests.append(np.array(importances['test'])[:,1:,:])\n",
    "        else:\n",
    "            all_importance_tests.append(np.array(importances['test']))\n",
    "        #meta_explain = MetaExplain(importance_train, feature_names)\n",
    "    all_importance_tests = np.array(all_importance_tests)\n",
    "    consistency[fi_name] = gm.consistency(all_importance_tests[:,:,idf,:])\n",
    "    print(fi_name, np.mean(consistency[fi_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 0.5102526794165372\n",
      "Median 0.4026272834916691\n",
      "RuleBased 0.3628088695564005\n"
     ]
    }
   ],
   "source": [
    "consistency_meta = {}\n",
    "for idf, meta_name in enumerate(meta_names):\n",
    "    all_importance_tests = []\n",
    "    for neural_name, neural_type in predict_functions.items():\n",
    "        all_importance_tests.append(np.array(meta_interpretations_test[neural_name]))\n",
    "    all_importance_tests = np.array(all_importance_tests)\n",
    "    consistency_meta[meta_name] = gm.consistency(all_importance_tests[:,:,idf,:])\n",
    "    print(meta_name, np.mean(consistency_meta[meta_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cb1b919848>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "con_df = pd.DataFrame({'IG':consistency['IG'], 'LRP':consistency['LRP'], 'LIME':consistency['LIME'], #'RAND':consistency['RAND'], \n",
    "                        'Average':consistency_meta['Average'], 'Median':consistency_meta['Median'], 'MetaLion':consistency_meta['RuleBased']})\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(con_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "con_df_models = pd.DataFrame({'IG':consistency['IG'], 'LRP':consistency['LRP'], 'LIME':consistency['LIME'], 'RAND':consistency['RAND']})\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring AUPRC for the meta inXAI technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for lNN\n",
      "Starting evaluation for NN\n",
      "Starting evaluation for cNN\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "pd_x_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "ct = ColumnTransformer([('_INXAI_normal_noise_perturber', NormalNoisePerturber(scale=2),pd_x_test.columns)])\n",
    "auprc = {}\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    meta_names = ['Average', 'Median', 'RuleBased']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_test = np.array(importances['test'])\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    model_auprc = []\n",
    "    for idf,fi_name in enumerate(fi_names):\n",
    "        mean_fi = importance_test[:,idf,:].mean(axis=0)\n",
    "        model_auprc.append(gm.gradual_perturbation(model=models[neural_name], X=pd_x_test, y=y_test, column_transformer=ct, importances_orig=mean_fi, \n",
    "                                        resolution=50,  count_per_step=10, plot=False, task='c'))\n",
    "    auprc[neural_name] = model_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lNN\n",
      "Inherent 0.06326359832635982\n",
      "IG 0.06715481171548116\n",
      "LRP 0.06478661087866106\n",
      "LIME 0.05864435146443513\n",
      "RAND 0.062133891213389074\n",
      "NN\n",
      "IG 0.13591631799163184\n",
      "LRP 0.13662761506276155\n",
      "LIME 0.13839330543933062\n",
      "RAND 0.13635146443514648\n",
      "cNN\n",
      "IG 0.14191631799163176\n",
      "LRP 0.1435564853556485\n",
      "LIME 0.14127196652719662\n",
      "RAND 0.1411380753138075\n"
     ]
    }
   ],
   "source": [
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    print(neural_name)\n",
    "    for idf, auprc_score in enumerate(auprc[neural_name]):\n",
    "        print(fi_names[idf], np.mean(auprc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "auprc_df_lnn = pd.DataFrame({'IG':[auc(np.linspace(0, 1, 50),auprc['lNN'][1])], 'LRP':[auc(np.linspace(0, 1, 50),auprc['lNN'][2])], 'LIME':[auc(np.linspace(0, 1, 50),auprc['lNN'][3])], 'RAND':[auc(np.linspace(0, 1, 50),auprc['lNN'][4])]})\n",
    "auprc_df_nn = pd.DataFrame({'IG':[auc(np.linspace(0, 1, 50),auprc['NN'][0])], 'LRP':[auc(np.linspace(0, 1, 50),auprc['NN'][1])], 'LIME':[auc(np.linspace(0, 1, 50),auprc['NN'][2])], 'RAND':[auc(np.linspace(0, 1, 50),auprc['NN'][3])]})\n",
    "auprc_df_cnn = pd.DataFrame({'IG':[auc(np.linspace(0, 1, 50),auprc['cNN'][0])], 'LRP':[auc(np.linspace(0, 1, 50),auprc['cNN'][1])], 'LIME':[auc(np.linspace(0, 1, 50),auprc['cNN'][2])], 'RAND':[auc(np.linspace(0, 1, 50),auprc['cNN'][3])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_alpha = 0.2\n",
    "lip_alpha=20\n",
    "auc_alpha=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IG</th>\n",
       "      <th>LRP</th>\n",
       "      <th>LIME</th>\n",
       "      <th>RAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.574689</td>\n",
       "      <td>21.633009</td>\n",
       "      <td>21.799824</td>\n",
       "      <td>21.802381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IG        LRP       LIME       RAND\n",
       "0  21.574689  21.633009  21.799824  21.802381"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = cons_alpha*con_df_models.iloc[33]+lip_alpha*lip_df_lnn.iloc[33]+auc_alpha/auprc_df_lnn\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for lNN\n",
      "inXAI 0.933781808440685\n",
      "Starting evaluation for NN\n",
      "inXAI 0.8029525206358832\n",
      "Starting evaluation for cNN\n",
      "inXAI 0.7973275413397637\n"
     ]
    }
   ],
   "source": [
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_test = np.array(importances['test'])\n",
    "    inxai = []\n",
    "    for idf, instance in enumerate(X_test):\n",
    "        if neural_name == 'lNN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_lnn.iloc[idf]+auc_alpha/auprc_df_lnn\n",
    "            met = weights.dot(importance_test[idf][1:])/weights.sum().sum()\n",
    "        elif neural_name == 'NN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_nn.iloc[idf]+auc_alpha/auprc_df_nn\n",
    "            met = weights.dot(importance_test[idf])/weights.sum().sum()\n",
    "        else:\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_cnn.iloc[idf]+auc_alpha/auprc_df_cnn\n",
    "            met = weights.dot(importance_test[idf])/weights.sum().sum()\n",
    "        inxai.append(met)\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    inxai_stability = gm.stability(pd.DataFrame(X_test), inxai ,epsilon=0.3)\n",
    "    print('inXAI', np.mean(inxai_stability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inXAI 0.8894660349182234\n"
     ]
    }
   ],
   "source": [
    "all_importance_tests = []\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    if neural_name == 'lNN':\n",
    "        per_neural = np.array(importances['test'])[:,1:,:]\n",
    "    else:\n",
    "        per_neural = np.array(importances['test'])\n",
    "    \n",
    "    for idf, instance in enumerate(X_test):\n",
    "        if neural_name == 'lNN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_lnn.iloc[idf]+auc_alpha/auprc_df_lnn\n",
    "            met = weights.dot(per_neural[idf])/weights.sum().sum()\n",
    "        elif neural_name == 'NN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_nn.iloc[idf]+auc_alpha/auprc_df_nn\n",
    "            met = weights.dot(per_neural[idf])/weights.sum().sum()\n",
    "        else:\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_cnn.iloc[idf]+auc_alpha/auprc_df_cnn\n",
    "            met = weights.dot(per_neural[idf])/weights.sum().sum()\n",
    "    all_importance_tests.append(met)\n",
    "all_importance_tests = np.array(all_importance_tests)\n",
    "inxai_consistency = gm.consistency(all_importance_tests)\n",
    "print('inXAI', np.mean(inxai_consistency))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfulness and Complexity evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_lNN, fi_IG_lNN, fi_LRP_lNN, fi_lime, fi_random]\n",
    "        fi_names = ['Inherent', 'IG', 'LRP', 'LIME', 'RAND']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_IG_NN, fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_IG_cNN, fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['IG', 'LRP', 'LIME', 'RAND']\n",
    "    meta_names = ['Average', 'Median', 'RuleBased']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "    meta_explain = MetaExplain(importance_train, feature_names)\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    for noise in ['weak', 'normal', 'strong']:\n",
    "        for delta in [0 , 0.0001, 0.001, 0.01, 0.1]:\n",
    "            my_altruist = Altruist(\n",
    "                neural_type, X_train, fi_techniques, feature_names, level=noise, delta=delta)\n",
    "            fis_scores = []\n",
    "            meta_scores = []\n",
    "            nzw_scores = []\n",
    "            nzw_scores_delta = []\n",
    "            for i in fi_techniques:\n",
    "                fis_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for i in meta_names:\n",
    "                meta_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for j in range(len(X_test)):\n",
    "                my_altruist.fis = len(fi_techniques)\n",
    "                a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "                for i in range(len(importance_test[j])):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in importance_test[j][i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i].append(cnzw)\n",
    "                    nzw_scores_delta[i].append(cnzwt)\n",
    "                b = np.array(a[-1])\n",
    "                for i in range(len(a[0])):\n",
    "                    fis_scores[i].append(len(a[0][i]))\n",
    "                temp_meta = []\n",
    "                temp_meta.append(meta_explain.meta_avg(b))\n",
    "                temp_meta.append(meta_explain.meta_median(b))\n",
    "                temp_meta.append(meta_explain.meta_rule_based(a[0], a[2], b))\n",
    "                for i in range(len(temp_meta)):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in temp_meta[i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i+len(importance_test[j])].append(cnzw)\n",
    "                    nzw_scores_delta[i+len(importance_test[j])].append(cnzwt)\n",
    "                my_altruist.fis = len(meta_names)\n",
    "                a = my_altruist.find_untruthful(X_test[j], temp_meta)\n",
    "                for i in range(len(a[0])):\n",
    "                    meta_scores[i].append(len(a[0][i]))\n",
    "            count = 0\n",
    "            row = [neural_name, noise, delta]\n",
    "            for fis_score in fis_scores:\n",
    "                row.append(np.array(fis_score).mean())\n",
    "            for meta_score in meta_scores:\n",
    "                row.append(np.array(meta_score).mean())\n",
    "            with open('D2_'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)\n",
    "            row = [neural_name, noise, delta]\n",
    "            all_names = fi_names+meta_names\n",
    "            for aname in range(len(all_names)):\n",
    "                row.append(np.array(nzw_scores[aname]).mean())\n",
    "                row.append(np.array(nzw_scores_delta[aname]).mean())\n",
    "            with open('D2_NZW_'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truthfulness and NZW for inXAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 5, 12)\n",
      "(239, 1, 12)\n",
      "Starting evaluation for lNN\n",
      "(239, 4, 12)\n",
      "(239, 1, 12)\n",
      "Starting evaluation for NN\n",
      "(239, 4, 12)\n",
      "(239, 1, 12)\n",
      "Starting evaluation for cNN\n"
     ]
    }
   ],
   "source": [
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'lNN':\n",
    "        fi_techniques = [fi_random]\n",
    "        fi_names = ['inXAI']\n",
    "    elif neural_name == 'NN':\n",
    "        fi_techniques = [fi_random]\n",
    "        fi_names = ['inXAI']\n",
    "    else:\n",
    "        fi_techniques = [fi_random]\n",
    "        fi_names = ['inXAI']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "    new_test = []\n",
    "    for idf, instance in enumerate(X_test):\n",
    "        if neural_name == 'lNN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_lnn.iloc[idf]+auc_alpha/auprc_df_lnn\n",
    "            met = weights.dot(importance_test[idf][1:])/weights.sum().sum()\n",
    "        elif neural_name == 'NN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_nn.iloc[idf]+auc_alpha/auprc_df_nn\n",
    "            met = weights.dot(importance_test[idf])/weights.sum().sum()\n",
    "        else:\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_cnn.iloc[idf]+auc_alpha/auprc_df_cnn\n",
    "            met = weights.dot(importance_test[idf])/weights.sum().sum()\n",
    "        new_test.append([met])\n",
    "    importance_test = np.array(new_test)\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    for noise in ['weak', 'normal', 'strong']:\n",
    "        for delta in [0 , 0.0001, 0.001, 0.01, 0.1]:\n",
    "            my_altruist = Altruist(\n",
    "                neural_type, X_train, fi_techniques, feature_names, level=noise, delta=delta)\n",
    "            fis_scores = []\n",
    "            meta_scores = []\n",
    "            nzw_scores = []\n",
    "            nzw_scores_delta = []\n",
    "            for i in fi_techniques:\n",
    "                fis_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for i in meta_names:\n",
    "                meta_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for j in range(len(X_test)):\n",
    "                my_altruist.fis = len(fi_techniques)\n",
    "                a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "                for i in range(len(importance_test[j])):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in importance_test[j][i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i].append(cnzw)\n",
    "                    nzw_scores_delta[i].append(cnzwt)\n",
    "                b = np.array(a[-1])\n",
    "                for i in range(len(a[0])):\n",
    "                    fis_scores[i].append(len(a[0][i]))\n",
    "                \n",
    "            count = 0\n",
    "            row = [neural_name, noise, delta]\n",
    "            for fis_score in fis_scores:\n",
    "                row.append(np.array(fis_score).mean())\n",
    "            with open('D2_inxai'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)\n",
    "            row = [neural_name, noise, delta]\n",
    "            all_names = fi_names\n",
    "            for aname in range(len(all_names)):\n",
    "                row.append(np.array(nzw_scores[aname]).mean())\n",
    "                row.append(np.array(nzw_scores_delta[aname]).mean())\n",
    "            with open('D2_NZW_inxai'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to produce $f$ atom type arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_altruist = Altruist(neural_type, X_train, fi_techniques, feature_names,\n",
    "                       level=noise, delta=delta, args=True)  # Enable args=True\n",
    "# After running the find_untruthful method, the last element of the returned elements are the arguments for each interpretation technqiue\n",
    "a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "arguments = a[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore one argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The alteration (INC) did not happen, as the feature value had the max value',\n",
       " \"$f_{car, DEC}$: The evaluation of the alteration of $car$'s value to $0.9903$ ($DEC$) was performed and the model's behaviour was as expected $Increased$ (0.4386 to 0.4442), according to its importance $z_{car}=-0.63$.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments[0][1]  # 0 indicates the interpretation technique, and 1 the feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for NN\n",
      "Results for: Noise -> normal  Delta -> 0.0001\n",
      "\t NZW:\n",
      "Starting evaluation for cNN\n",
      "Results for: Noise -> normal  Delta -> 0.0001\n",
      "\t NZW:\n"
     ]
    }
   ],
   "source": [
    "predict_functions = {'NN': predict_NN, 'cNN': predict_cNN}\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'NN':\n",
    "        fi_techniques = [fi_LRP_NN, fi_lime, fi_random]\n",
    "        fi_names = ['LRP', 'LIME', 'RAND']\n",
    "    else:\n",
    "        fi_techniques = [fi_LRP_cNN, fi_lime, fi_random]\n",
    "        fi_names = ['LRP', 'LIME', 'RAND']\n",
    "    meta_names = ['Average', 'Median', 'RuleBased']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "    meta_explain = MetaExplain(importance_train, feature_names)\n",
    "    importance_train = np.delete(importance_train, 3, axis=1)\n",
    "    importance_test = np.delete(importance_test, 3, axis=1)\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    for noise in ['normal']:\n",
    "        for delta in [0.0001]:\n",
    "            my_altruist = Altruist(neural_type, X_train, fi_techniques,\n",
    "                                   feature_names, prolog=False, level=noise, delta=delta)\n",
    "            fis_scores = []\n",
    "            meta_scores = []\n",
    "            nzw_scores = []\n",
    "            nzw_scores_delta = []\n",
    "            for i in fi_techniques:\n",
    "                fis_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for i in meta_names:\n",
    "                meta_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for j in range(len(X_test)):\n",
    "                my_altruist.fis = len(fi_techniques)\n",
    "                a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "                for i in range(len(importance_test[j])):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in importance_test[j][i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i].append(cnzw)\n",
    "                    nzw_scores_delta[i].append(cnzwt)\n",
    "                b = np.array(a[-1])\n",
    "                for i in range(len(a[0])):\n",
    "                    fis_scores[i].append(len(a[0][i]))\n",
    "                temp_meta = []\n",
    "                temp_meta.append(meta_explain.meta_avg(b))\n",
    "                temp_meta.append(meta_explain.meta_median(b))\n",
    "                temp_meta.append(meta_explain.meta_rule_based(a[0], a[2], b))\n",
    "                for i in range(len(temp_meta)):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in temp_meta[i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i+len(importance_test[j])].append(cnzw)\n",
    "                    nzw_scores_delta[i+len(importance_test[j])].append(cnzwt)\n",
    "                my_altruist.fis = len(meta_names)\n",
    "                a = my_altruist.find_untruthful(X_test[j], temp_meta)\n",
    "                for i in range(len(a[0])):\n",
    "                    meta_scores[i].append(len(a[0][i]))\n",
    "            count = 0\n",
    "            row = [neural_name, noise, delta]\n",
    "            for fis_score in fis_scores:\n",
    "                row.append(np.array(fis_score).mean())\n",
    "            for meta_score in meta_scores:\n",
    "                row.append(np.array(meta_score).mean())\n",
    "            with open('D2_Ablation_Study_'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)\n",
    "            row = [neural_name, noise, delta]\n",
    "            all_names = fi_names+meta_names\n",
    "            for aname in range(len(all_names)):\n",
    "                row.append(np.array(nzw_scores[aname]).mean())\n",
    "                row.append(np.array(nzw_scores_delta[aname]).mean())\n",
    "            with open('D2_Ablation_Study_NZW_'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for NN\n",
      "Starting evaluation for cNN\n"
     ]
    }
   ],
   "source": [
    "predict_functions = {'NN': predict_NN, 'cNN': predict_cNN}\n",
    "for neural_name, neural_type in predict_functions.items():\n",
    "    if neural_name == 'NN':\n",
    "        fi_techniques = [fi_random]\n",
    "        fi_names = ['inXAI']\n",
    "    else:\n",
    "        fi_techniques = [fi_random]\n",
    "        fi_names = ['inXAI']\n",
    "\n",
    "    with open(weights_path+'D2_'+neural_name+'.txt') as json_file:\n",
    "        importances = json.load(json_file)\n",
    "    importance_train = np.array(importances['train'])\n",
    "    importance_test = np.array(importances['test'])\n",
    "\n",
    "    fi = 3\n",
    "    importance_train = np.delete(importance_train, fi, axis=1) #change this manually\n",
    "    importance_test = np.delete(importance_test, fi, axis=1)\n",
    "    new_test = []\n",
    "    for idf, instance in enumerate(X_test):\n",
    "        if neural_name == 'NN':\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_nn.iloc[idf]+auc_alpha/auprc_df_nn\n",
    "            met = weights.drop(weights.columns[[fi]],axis = 1).dot(importance_test[idf])/weights.sum().sum()\n",
    "        else:\n",
    "            weights = cons_alpha*con_df_models.iloc[idf]+lip_alpha*lip_df_cnn.iloc[idf]+auc_alpha/auprc_df_cnn\n",
    "            met = weights.drop(weights.columns[[fi]],axis = 1).dot(importance_test[idf])/weights.sum().sum()\n",
    "        new_test.append([met])\n",
    "    importance_test = np.array(new_test)\n",
    "\n",
    "    print('Starting evaluation for', neural_name)\n",
    "    for noise in ['normal']:\n",
    "        for delta in [0.0001]:\n",
    "            my_altruist = Altruist(\n",
    "                neural_type, X_train, fi_techniques, feature_names, level=noise, delta=delta)\n",
    "            fis_scores = []\n",
    "            meta_scores = []\n",
    "            nzw_scores = []\n",
    "            nzw_scores_delta = []\n",
    "            for i in fi_techniques:\n",
    "                fis_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for i in meta_names:\n",
    "                meta_scores.append([])\n",
    "                nzw_scores.append([])\n",
    "                nzw_scores_delta.append([])\n",
    "            for j in range(len(X_test)):\n",
    "                my_altruist.fis = len(fi_techniques)\n",
    "                a = my_altruist.find_untruthful(X_test[j], importance_test[j])\n",
    "                for i in range(len(importance_test[j])):\n",
    "                    cnzw = 0\n",
    "                    cnzwt = 0\n",
    "                    for k in importance_test[j][i]:\n",
    "                        if abs(k) > 0:\n",
    "                            cnzw += 1\n",
    "                        if abs(k) > delta:\n",
    "                            cnzwt += 1\n",
    "                    nzw_scores[i].append(cnzw)\n",
    "                    nzw_scores_delta[i].append(cnzwt)\n",
    "                b = np.array(a[-1])\n",
    "                for i in range(len(a[0])):\n",
    "                    fis_scores[i].append(len(a[0][i]))\n",
    "                \n",
    "            count = 0\n",
    "            row = [neural_name, noise, delta]\n",
    "            for fis_score in fis_scores:\n",
    "                row.append(np.array(fis_score).mean())\n",
    "            with open('D2_Ablation_Study_inxai'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)\n",
    "            row = [neural_name, noise, delta]\n",
    "            all_names = fi_names\n",
    "            for aname in range(len(all_names)):\n",
    "                row.append(np.array(nzw_scores[aname]).mean())\n",
    "                row.append(np.array(nzw_scores_delta[aname]).mean())\n",
    "            with open('D2_Ablation_Study_NZW_inxai'+neural_name+'.csv', 'a', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd5e8c6fff498abb6f50ff8dbceb932bf4b3fcabb88a01361989616fd97963bd"
  },
  "kernelspec": {
   "display_name": "lionets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
